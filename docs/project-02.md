## CPU - GPU Parallel Training

The fact is that our CUDA backend is not much faster then CPU, and often have smaller memory compare to CPU, if we can utilize both CPU and GPU to train the model, we may archive something between 1.5x and 2x speedup?

